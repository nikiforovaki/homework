{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers evaluation and comparison\n",
    "Nikiforova Kristina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn import *\n",
    "%pylab inline\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2     3     4     5    6    7    8    9  ...   55   56   57  \\\n",
       "0  0.0  0.0  5.0  13.0   9.0   1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  12.0  13.0   5.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0   4.0  15.0  12.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "3  0.0  0.0  7.0  15.0  13.0   1.0  0.0  0.0  0.0  8.0  ...  0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0   1.0  11.0   0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "    58    59    60    61   62   63  target  \n",
       "0  6.0  13.0  10.0   0.0  0.0  0.0       0  \n",
       "1  0.0  11.0  16.0  10.0  0.0  0.0       1  \n",
       "2  0.0   3.0  11.0  16.0  9.0  0.0       2  \n",
       "3  7.0  13.0  13.0   9.0  0.0  0.0       3  \n",
       "4  0.0   2.0  16.0   4.0  0.0  0.0       4  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits = datasets.load_digits()\n",
    "df = pd.DataFrame(digits.data)\n",
    "df['target'] = digits.target\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1       2       3        4        5       6        7       8  \\\n",
       "0  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.3001  0.14710  0.2419   \n",
       "1  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869  0.07017  0.1812   \n",
       "2  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974  0.12790  0.2069   \n",
       "3  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414  0.10520  0.2597   \n",
       "4  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980  0.10430  0.1809   \n",
       "\n",
       "         9  ...     21      22      23      24      25      26      27  \\\n",
       "0  0.07871  ...  17.33  184.60  2019.0  0.1622  0.6656  0.7119  0.2654   \n",
       "1  0.05667  ...  23.41  158.80  1956.0  0.1238  0.1866  0.2416  0.1860   \n",
       "2  0.05999  ...  25.53  152.50  1709.0  0.1444  0.4245  0.4504  0.2430   \n",
       "3  0.09744  ...  26.50   98.87   567.7  0.2098  0.8663  0.6869  0.2575   \n",
       "4  0.05883  ...  16.67  152.20  1575.0  0.1374  0.2050  0.4000  0.1625   \n",
       "\n",
       "       28       29  target  \n",
       "0  0.4601  0.11890       0  \n",
       "1  0.2750  0.08902       0  \n",
       "2  0.3613  0.08758       0  \n",
       "3  0.6638  0.17300       0  \n",
       "4  0.2364  0.07678       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast_canсer = datasets.load_breast_cancer()\n",
    "bcf = pd.DataFrame(breast_canсer.data)\n",
    "bcf['target'] = breast_canсer.target\n",
    "bcf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     1     2     3      4     5     6     7     8     9    10    11  \\\n",
       "0  14.23  1.71  2.43  15.6  127.0  2.80  3.06  0.28  2.29  5.64  1.04  3.92   \n",
       "1  13.20  1.78  2.14  11.2  100.0  2.65  2.76  0.26  1.28  4.38  1.05  3.40   \n",
       "2  13.16  2.36  2.67  18.6  101.0  2.80  3.24  0.30  2.81  5.68  1.03  3.17   \n",
       "3  14.37  1.95  2.50  16.8  113.0  3.85  3.49  0.24  2.18  7.80  0.86  3.45   \n",
       "4  13.24  2.59  2.87  21.0  118.0  2.80  2.69  0.39  1.82  4.32  1.04  2.93   \n",
       "\n",
       "       12  target  \n",
       "0  1065.0       0  \n",
       "1  1050.0       0  \n",
       "2  1185.0       0  \n",
       "3  1480.0       0  \n",
       "4   735.0       0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine = datasets.load_wine()\n",
    "wf = pd.DataFrame(wine.data)\n",
    "wf['target'] = wine.target\n",
    "wf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### сonversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digits data size: 1797 instances \n",
      "Breast_cancer data size: 569 instances\n",
      "Wine data size: 178 instances\n"
     ]
    }
   ],
   "source": [
    "target_d =  df['target'] \n",
    "data_d = df.drop(columns = ['target'])\n",
    "\n",
    "target_bc = bcf['target'] \n",
    "data_bc = bcf.drop(columns = ['target'])\n",
    "\n",
    "target_w = wf['target'] \n",
    "data_w = wf.drop(columns = ['target'])\n",
    "\n",
    "print ('Digits data size: {} instances \\nBreast_cancer data size: {} instances\\nWine data size:'\n",
    "       ' {} instances'.format(len(data_d), len(data_bc),len(data_w)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for classifier settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def load_classifier(classifier, params, train_x, test_x, train_y, folds, scor): \n",
    "    grid = model_selection.GridSearchCV(classifier, params, refit=True, scoring=f1_scorer, iid = True,\n",
    "                                     cv=model_selection.StratifiedKFold(n_splits=folds))\n",
    "    grid_best = grid.fit(train_x, train_y)\n",
    "    print(\"Best hyper-parameters: {}\".format(grid_best.best_params_))\n",
    "    predictions = grid_best.predict(test_x)\n",
    "    #metrics.ploat_confusion_matrix(grid_best, test_data, test_labe)\n",
    "    f1 = metrics.f1_score(test_y, predictions, average='weighted')\n",
    "    print (\"F1 = {:.3f}\".format(f1))\n",
    "    #print(metrics.classification_report(test_y, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cross-validation predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def cross(model, test_x, test_y):\n",
    "    predictions = model_selection.cross_val_predict(model, test_x, test_y)\n",
    "    f1 = metrics.f1_score(test_y, predictions, average='weighted')\n",
    "    print('Cross-validation predictions:')\n",
    "    print (\"f1 = {:.3f}\".format(f1))\n",
    "    print(metrics.classification_report(test_y, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = model_selection.train_test_split(data_d, target_d, test_size = 0.2)\n",
    "folds = 5\n",
    "f1_scorer = metrics.make_scorer(metrics.f1_score, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.102\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       178\n",
      "           1       0.00      0.00      0.00       182\n",
      "           2       0.00      0.00      0.00       177\n",
      "           3       0.10      1.00      0.18       183\n",
      "           4       0.00      0.00      0.00       181\n",
      "           5       0.00      0.00      0.00       182\n",
      "           6       0.00      0.00      0.00       181\n",
      "           7       0.00      0.00      0.00       179\n",
      "           8       0.00      0.00      0.00       174\n",
      "           9       0.00      0.00      0.00       180\n",
      "\n",
      "    accuracy                           0.10      1797\n",
      "   macro avg       0.01      0.10      0.02      1797\n",
      "weighted avg       0.01      0.10      0.02      1797\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = dummy.DummyClassifier(strategy='most_frequent')\n",
    "model.fit (data_d, target_d)\n",
    "predictions = model.predict(data_d)\n",
    "accuracy_base = metrics.accuracy_score(target_d, predictions)\n",
    "print (\"Accuracy = {:.3f}\".format(accuracy_base))\n",
    "print(metrics.classification_report(target_d, predictions))\n",
    "\n",
    "#plot_confusion_matrix(model, data_d, target_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find best classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'C': 1, 'max_iter': 100, 'penalty': 'l1', 'tol': 0.001}\n",
      "F1 = 0.969\n",
      "Cross-validation predictions:\n",
      "f1 = 0.950\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97        43\n",
      "           1       0.86      0.95      0.90        39\n",
      "           2       1.00      0.97      0.98        32\n",
      "           3       0.95      0.95      0.95        40\n",
      "           4       1.00      0.98      0.99        46\n",
      "           5       0.96      0.90      0.93        29\n",
      "           6       1.00      1.00      1.00        35\n",
      "           7       1.00      1.00      1.00        27\n",
      "           8       0.85      0.85      0.85        33\n",
      "           9       0.97      0.89      0.93        36\n",
      "\n",
      "    accuracy                           0.95       360\n",
      "   macro avg       0.95      0.95      0.95       360\n",
      "weighted avg       0.95      0.95      0.95       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logistic_param = {'penalty': ['l1', 'l2'],'C': [1, 10, 100], 'max_iter': [100, 300],'tol': [1e-3, 1e-4]}\n",
    "logistic_classifier = linear_model.LogisticRegression(random_state=1, solver='liblinear')\n",
    "load_classifier(logistic_classifier,logistic_param,train_x, test_x, train_y, folds, f1_scorer)\n",
    "cross(logistic_classifier, test_x,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "F1 = 0.989\n",
      "Cross-validation predictions:\n",
      "f1 = 0.096\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.19      0.31        43\n",
      "           1       1.00      0.15      0.27        39\n",
      "           2       0.00      0.00      0.00        32\n",
      "           3       0.00      0.00      0.00        40\n",
      "           4       0.13      1.00      0.23        46\n",
      "           5       0.00      0.00      0.00        29\n",
      "           6       0.00      0.00      0.00        35\n",
      "           7       0.00      0.00      0.00        27\n",
      "           8       0.00      0.00      0.00        33\n",
      "           9       0.00      0.00      0.00        36\n",
      "\n",
      "    accuracy                           0.17       360\n",
      "   macro avg       0.21      0.13      0.08       360\n",
      "weighted avg       0.24      0.17      0.10       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc_param = {'kernel': ['linear','rbf'], 'gamma': [1e-4, 'scale'], 'C': [1, 10]}\n",
    "svc_classifier = svm.SVC(probability=True)\n",
    "load_classifier(svc_classifier, svc_param, train_x, test_x, train_y, folds, f1_scorer)\n",
    "cross(svc_classifier, test_x,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'max_depth': 10, 'max_features': None, 'min_samples_leaf': 1, 'presort': True}\n",
      "F1 = 0.863\n",
      "Cross-validation predictions:\n",
      "f1 = 0.718\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90        43\n",
      "           1       0.64      0.74      0.69        39\n",
      "           2       0.79      0.72      0.75        32\n",
      "           3       0.68      0.70      0.69        40\n",
      "           4       0.83      0.74      0.78        46\n",
      "           5       0.63      0.59      0.61        29\n",
      "           6       0.88      0.80      0.84        35\n",
      "           7       0.73      0.81      0.77        27\n",
      "           8       0.41      0.45      0.43        33\n",
      "           9       0.69      0.61      0.65        36\n",
      "\n",
      "    accuracy                           0.72       360\n",
      "   macro avg       0.72      0.71      0.71       360\n",
      "weighted avg       0.72      0.72      0.72       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_param = {'presort':[True, False], 'max_depth' : [ 2, 3, 5, 7, 10], 'max_features' : ['auto', 1, 2, 3, None],\n",
    "                  'min_samples_leaf' : [1, 2, 3, 4, 5]}\n",
    "decision_classifier = tree.DecisionTreeClassifier(random_state=1)\n",
    "load_classifier(decision_classifier, decision_param ,train_x, test_x, train_y,folds, f1_scorer)\n",
    "cross(decision_classifier, test_x,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'var_smoothing': 0.001}\n",
      "F1 = 0.895\n",
      "Cross-validation predictions:\n",
      "f1 = 0.815\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96        43\n",
      "           1       0.72      0.72      0.72        39\n",
      "           2       0.94      0.94      0.94        32\n",
      "           3       0.75      0.68      0.71        40\n",
      "           4       0.93      0.85      0.89        46\n",
      "           5       0.77      0.93      0.84        29\n",
      "           6       0.94      0.86      0.90        35\n",
      "           7       0.77      0.89      0.83        27\n",
      "           8       0.60      0.79      0.68        33\n",
      "           9       0.73      0.61      0.67        36\n",
      "\n",
      "    accuracy                           0.81       360\n",
      "   macro avg       0.82      0.82      0.81       360\n",
      "weighted avg       0.82      0.81      0.81       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "naive_param = {'var_smoothing' : [ 1e-3, 1e-5, 1e-7, 1e-9]}\n",
    "naive_classifier = naive_bayes.GaussianNB()\n",
    "load_classifier(naive_classifier, naive_param,train_x, test_x, train_y, folds, f1_scorer)\n",
    "cross(naive_classifier, test_x,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestCLassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'max_depth': None, 'max_features': 'log2', 'n_estimators': 250}\n",
      "F1 = 0.980\n",
      "Cross-validation predictions:\n",
      "f1 = 0.859\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91        43\n",
      "           1       0.90      0.92      0.91        39\n",
      "           2       0.86      0.94      0.90        32\n",
      "           3       0.79      0.78      0.78        40\n",
      "           4       0.88      0.93      0.91        46\n",
      "           5       0.88      0.76      0.81        29\n",
      "           6       0.92      0.94      0.93        35\n",
      "           7       0.87      0.96      0.91        27\n",
      "           8       0.71      0.67      0.69        33\n",
      "           9       0.88      0.78      0.82        36\n",
      "\n",
      "    accuracy                           0.86       360\n",
      "   macro avg       0.86      0.86      0.86       360\n",
      "weighted avg       0.86      0.86      0.86       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "forest_param = {'max_depth' : [None, 8, 10, 13], 'n_estimators' : [10, 50, 100, 250], 'max_features' : ['auto', 'log2']}\n",
    "forest_classifier = ensemble.RandomForestClassifier(random_state=1)\n",
    "load_classifier(forest_classifier, forest_param, train_x, test_x, train_y,folds, f1_scorer)\n",
    "cross(forest_classifier, test_x,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'algorithm': 'SAMME', 'learning_rate': 1, 'n_estimators': 100}\n",
      "F1 = 0.803\n",
      "Cross-validation predictions:\n",
      "f1 = 0.229\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.51      0.58        43\n",
      "           1       0.00      0.00      0.00        39\n",
      "           2       0.13      0.31      0.18        32\n",
      "           3       0.19      0.38      0.25        40\n",
      "           4       0.23      0.48      0.31        46\n",
      "           5       0.80      0.14      0.24        29\n",
      "           6       0.38      0.37      0.38        35\n",
      "           7       0.00      0.00      0.00        27\n",
      "           8       0.00      0.00      0.00        33\n",
      "           9       0.23      0.19      0.21        36\n",
      "\n",
      "    accuracy                           0.26       360\n",
      "   macro avg       0.26      0.24      0.21       360\n",
      "weighted avg       0.26      0.26      0.23       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "boost_param = {'n_estimators' : [50, 100], 'learning_rate' : [1, 0.7], 'algorithm': ['SAMME', 'SAMME.R']}\n",
    "boost_classifier = ensemble.AdaBoostClassifier()\n",
    "load_classifier(boost_classifier, boost_param, train_x, test_x, train_y,folds, f1_scorer)\n",
    "cross(boost_classifier, test_x,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VotingCLassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'flatten_transform': True, 'voting': 'hard'}\n",
      "F1 = 0.964\n",
      "Cross-validation predictions:\n",
      "f1 = 0.931\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        43\n",
      "           1       0.88      0.95      0.91        39\n",
      "           2       1.00      0.97      0.98        32\n",
      "           3       0.88      0.88      0.88        40\n",
      "           4       0.98      0.93      0.96        46\n",
      "           5       1.00      0.90      0.95        29\n",
      "           6       1.00      1.00      1.00        35\n",
      "           7       0.90      0.96      0.93        27\n",
      "           8       0.83      0.88      0.85        33\n",
      "           9       0.91      0.83      0.87        36\n",
      "\n",
      "    accuracy                           0.93       360\n",
      "   macro avg       0.93      0.93      0.93       360\n",
      "weighted avg       0.93      0.93      0.93       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "voting_param = {'voting' : ['hard', 'soft'], 'flatten_transform' :[True, False, None]}\n",
    "voting_classifier = ensemble.VotingClassifier(estimators=[('lr', logistic_classifier), \n",
    "                                            ('rf', ensemble.RandomForestClassifier(n_estimators=50, random_state=1)), \n",
    "                                            ('gnb', naive_classifier)])\n",
    "load_classifier(voting_classifier, voting_param, train_x, test_x, train_y, folds, f1_scorer)\n",
    "cross(voting_classifier, test_x,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## breast_cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.627\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       212\n",
      "           1       0.63      1.00      0.77       357\n",
      "\n",
      "    accuracy                           0.63       569\n",
      "   macro avg       0.31      0.50      0.39       569\n",
      "weighted avg       0.39      0.63      0.48       569\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = dummy.DummyClassifier(strategy='most_frequent')\n",
    "model.fit (data_bc, target_bc)\n",
    "predictions = model.predict(data_bc)\n",
    "accuracy_base = metrics.accuracy_score(target_bc, predictions)\n",
    "print (\"Accuracy = {:.3f}\".format(accuracy_base))\n",
    "print(metrics.classification_report(target_bc, predictions))\n",
    "#metrics.plot_confusion_matrix(model, data_d, target_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find best classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = model_selection.train_test_split(data_bc, target_bc, test_size = 0.2)\n",
    "folds = 5\n",
    "f1_scorer  = metrics.make_scorer(metrics.f1_score, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'C': 100, 'max_iter': 100, 'penalty': 'l1', 'tol': 0.001}\n",
      "F1 = 0.938\n",
      "Cross-validation predictions:\n",
      "f1 = 0.912\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.86      0.88        44\n",
      "           1       0.92      0.94      0.93        70\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.91      0.90      0.91       114\n",
      "weighted avg       0.91      0.91      0.91       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "load_classifier(logistic_classifier,logistic_param,train_x, test_x, train_y, folds, f1_scorer)\n",
    "cross(logistic_classifier, test_x,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'C': 10, 'gamma': 0.0001, 'kernel': 'linear'}\n",
      "F1 = 0.929\n",
      "Cross-validation predictions:\n",
      "f1 = 0.467\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        44\n",
      "           1       0.61      1.00      0.76        70\n",
      "\n",
      "    accuracy                           0.61       114\n",
      "   macro avg       0.31      0.50      0.38       114\n",
      "weighted avg       0.38      0.61      0.47       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "load_classifier(svc_classifier, svc_param, train_x, test_x, train_y, folds, f1_scorer)\n",
    "cross(svc_classifier, test_x,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'max_depth': 3, 'max_features': 2, 'min_samples_leaf': 2, 'presort': True}\n",
      "F1 = 0.904\n",
      "Cross-validation predictions:\n",
      "f1 = 0.938\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.89      0.92        44\n",
      "           1       0.93      0.97      0.95        70\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.94      0.93      0.93       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "load_classifier(decision_classifier, decision_param ,train_x, test_x, train_y,folds, f1_scorer)\n",
    "cross(decision_classifier, test_x,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'var_smoothing': 1e-09}\n",
      "F1 = 0.911\n",
      "Cross-validation predictions:\n",
      "f1 = 0.930\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91        44\n",
      "           1       0.93      0.96      0.94        70\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.93      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "load_classifier(naive_classifier, naive_param,train_x, test_x, train_y, folds, f1_scorer)\n",
    "cross(naive_classifier, test_x,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestCLassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'max_depth': None, 'max_features': 'auto', 'n_estimators': 250}\n",
      "F1 = 0.938\n",
      "Cross-validation predictions:\n",
      "f1 = 0.921\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90        44\n",
      "           1       0.93      0.94      0.94        70\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.92      0.91      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "load_classifier(forest_classifier, forest_param, train_x, test_x, train_y,folds, f1_scorer)\n",
    "cross(forest_classifier, test_x,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'algorithm': 'SAMME', 'learning_rate': 1, 'n_estimators': 50}\n",
      "F1 = 0.947\n",
      "Cross-validation predictions:\n",
      "f1 = 0.938\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92        44\n",
      "           1       0.94      0.96      0.95        70\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.94      0.93      0.93       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "load_classifier(boost_classifier, boost_param, train_x, test_x, train_y,folds, f1_scorer)\n",
    "cross(boost_classifier, test_x,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VotingCLassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'flatten_transform': True, 'voting': 'soft'}\n",
      "F1 = 0.911\n",
      "Cross-validation predictions:\n",
      "f1 = 0.938\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92        44\n",
      "           1       0.94      0.96      0.95        70\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.94      0.93      0.93       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "load_classifier(voting_classifier, voting_param, train_x, test_x, train_y, folds, f1_scorer)\n",
    "cross(voting_classifier, test_x,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.399\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        59\n",
      "           1       0.40      1.00      0.57        71\n",
      "           2       0.00      0.00      0.00        48\n",
      "\n",
      "    accuracy                           0.40       178\n",
      "   macro avg       0.13      0.33      0.19       178\n",
      "weighted avg       0.16      0.40      0.23       178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = dummy.DummyClassifier(strategy='most_frequent')\n",
    "model.fit (data_w, target_w)\n",
    "predictions = model.predict(data_w)\n",
    "accuracy_base = metrics.accuracy_score(target_w, predictions)\n",
    "print (\"Accuracy = {:.3f}\".format(accuracy_base))\n",
    "print(metrics.classification_report(target_w, predictions))\n",
    "#metrics.plot_confusion_matrix(model, data_d, target_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find best classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = model_selection.train_test_split(data_w, target_w, test_size = 0.2)\n",
    "folds = 5\n",
    "f1_scorer = metrics.make_scorer(metrics.f1_score, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'C': 10, 'max_iter': 100, 'penalty': 'l1', 'tol': 0.001}\n",
      "F1 = 0.944\n",
      "Cross-validation predictions:\n",
      "f1 = 0.750\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86        14\n",
      "           1       0.77      0.77      0.77        13\n",
      "           2       0.56      0.56      0.56         9\n",
      "\n",
      "    accuracy                           0.75        36\n",
      "   macro avg       0.73      0.73      0.73        36\n",
      "weighted avg       0.75      0.75      0.75        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "load_classifier(logistic_classifier,logistic_param,train_x, test_x, train_y, folds, f1_scorer)\n",
    "cross(logistic_classifier, test_x,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'C': 1, 'gamma': 0.0001, 'kernel': 'linear'}\n",
      "F1 = 0.944\n",
      "Cross-validation predictions:\n",
      "f1 = 0.320\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.71      0.51        14\n",
      "           1       0.36      0.31      0.33        13\n",
      "           2       0.00      0.00      0.00         9\n",
      "\n",
      "    accuracy                           0.39        36\n",
      "   macro avg       0.25      0.34      0.28        36\n",
      "weighted avg       0.29      0.39      0.32        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "load_classifier(svc_classifier, svc_param, train_x, test_x, train_y, folds, f1_scorer)\n",
    "cross(svc_classifier, test_x,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'max_depth': 5, 'max_features': None, 'min_samples_leaf': 3, 'presort': True}\n",
      "F1 = 0.889\n",
      "Cross-validation predictions:\n",
      "f1 = 0.747\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.86      0.83        14\n",
      "           1       0.67      0.62      0.64        13\n",
      "           2       0.78      0.78      0.78         9\n",
      "\n",
      "    accuracy                           0.75        36\n",
      "   macro avg       0.75      0.75      0.75        36\n",
      "weighted avg       0.75      0.75      0.75        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "load_classifier(decision_classifier, decision_param ,train_x, test_x, train_y,folds, f1_scorer)\n",
    "cross(decision_classifier, test_x,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'var_smoothing': 1e-05}\n",
      "F1 = 0.916\n",
      "Cross-validation predictions:\n",
      "f1 = 0.972\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       0.93      1.00      0.96        13\n",
      "           2       1.00      0.89      0.94         9\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.98      0.96      0.97        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "load_classifier(naive_classifier, naive_param,train_x, test_x, train_y, folds, f1_scorer)\n",
    "cross(naive_classifier, test_x,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestCLassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'max_depth': None, 'max_features': 'auto', 'n_estimators': 250}\n",
      "F1 = 1.000\n",
      "Cross-validation predictions:\n",
      "f1 = 0.886\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93        14\n",
      "           1       0.91      0.77      0.83        13\n",
      "           2       0.89      0.89      0.89         9\n",
      "\n",
      "    accuracy                           0.89        36\n",
      "   macro avg       0.89      0.89      0.89        36\n",
      "weighted avg       0.89      0.89      0.89        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "load_classifier(forest_classifier, forest_param, train_x, test_x, train_y,folds, f1_scorer)\n",
    "cross(forest_classifier, test_x,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'algorithm': 'SAMME.R', 'learning_rate': 0.7, 'n_estimators': 100}\n",
      "F1 = 0.972\n",
      "Cross-validation predictions:\n",
      "f1 = 0.728\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.71      0.69        14\n",
      "           1       0.64      0.69      0.67        13\n",
      "           2       1.00      0.78      0.88         9\n",
      "\n",
      "    accuracy                           0.72        36\n",
      "   macro avg       0.77      0.73      0.74        36\n",
      "weighted avg       0.74      0.72      0.73        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "load_classifier(boost_classifier, boost_param, train_x, test_x, train_y,folds, f1_scorer)\n",
    "cross(boost_classifier, test_x,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VotingCLassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters: {'flatten_transform': True, 'voting': 'hard'}\n",
      "F1 = 1.000\n",
      "Cross-validation predictions:\n",
      "f1 = 0.972\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       0.93      1.00      0.96        13\n",
      "           2       1.00      0.89      0.94         9\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.98      0.96      0.97        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "load_classifier(voting_classifier, voting_param, train_x, test_x, train_y, folds, f1_scorer)\n",
    "cross(voting_classifier, test_x,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "Digits\n",
    "Baseline: 0.102\n",
    "Logistic Regression: 0,969\n",
    "SVM: 0.989\n",
    "Decision Tree Classifier: 0.863\n",
    "Naive Bayes: 0.895\n",
    "Random Forest Classifier:0.980\n",
    "Ada Boost Classifier: 0.803\n",
    "Voting Classifier: 0.964"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "breast_cancer\n",
    "Baseline: 0.627\n",
    "Logistic Regression: 0.938\n",
    "SVM: 0.929\n",
    "Decision Tree Classifier: 0.904\n",
    "Naive Bayes: 0.911\n",
    "Random Forest Classifier:0.938\n",
    "Ada Boost Classifier: 0.847\n",
    "Voting Classifier: 0.911"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wine \n",
    "breast_cancer\n",
    "Baseline: 0.399\n",
    "Logistic Regression: 0.944\n",
    "SVM: 0.944\n",
    "Decision Tree Classifier: 0.889\n",
    "Naive Bayes: 0.916\n",
    "Random Forest Classifier:1.000\n",
    "Ada Boost Classifier: 0.972\n",
    "Voting Classifier: 1.000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
